{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic-Agent base search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "Same dataset as the quickstart tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input1</th>\n",
       "      <th>input2</th>\n",
       "      <th>input3</th>\n",
       "      <th>input4</th>\n",
       "      <th>input5</th>\n",
       "      <th>input6</th>\n",
       "      <th>input7</th>\n",
       "      <th>input8</th>\n",
       "      <th>input9</th>\n",
       "      <th>input10</th>\n",
       "      <th>input11</th>\n",
       "      <th>input12</th>\n",
       "      <th>input13</th>\n",
       "      <th>input14</th>\n",
       "      <th>input15</th>\n",
       "      <th>input16</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input1  input2  input3  input4  input5  input6  input7  input8  input9  \\\n",
       "0    47.0   100.0    27.0    81.0    57.0    37.0    26.0     0.0     0.0   \n",
       "1     0.0    89.0    27.0   100.0    42.0    75.0    29.0    45.0    15.0   \n",
       "2     0.0    57.0    31.0    68.0    72.0    90.0   100.0   100.0    76.0   \n",
       "3     0.0   100.0     7.0    92.0     5.0    68.0    19.0    45.0    86.0   \n",
       "4     0.0    67.0    49.0    83.0   100.0   100.0    81.0    80.0    60.0   \n",
       "\n",
       "   input10  input11  input12  input13  input14  input15  input16 class  \n",
       "0     23.0     56.0     53.0    100.0     90.0     40.0     98.0     8  \n",
       "1     15.0     37.0      0.0     69.0      2.0    100.0      6.0     2  \n",
       "2     75.0     50.0     51.0     28.0     25.0     16.0      0.0     1  \n",
       "3     34.0    100.0     45.0     74.0     23.0     67.0      0.0     4  \n",
       "4     60.0     40.0     40.0     33.0     20.0     47.0      0.0     1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = openml.datasets.get_dataset(32)\n",
    "data, _, numerical, names = dataset.get_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (7694, 16), y_train: (7694, 1), X_val: (3298, 16), y_val: (3298, 1)\n",
      "Number of features: 16, number of classes: 1\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('class', axis=1)\n",
    "X = (X - X.min(axis=0))/(X.max(axis=0) - X.min(axis=0))\n",
    "y = data[[\"class\"]].astype(int)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}, X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"Number of features: {X.shape[1]}, number of classes: {y.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X = torch.FloatTensor(X.values)\n",
    "        self.y = torch.LongTensor(y.values)\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "train_set = CustomDataset(X_train, y_train)\n",
    "val_set = CustomDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Space\n",
    "\n",
    "In **DRAGON** the neural networks are represented as *Directed Acyclic Graphs (DAGs)*, where each node represents `nn.Module` layer, and the edges are the connection between them. Within the package, the DAGs are encoded using their adjaceny matrix. To know more about these objects, refer to the [Search Space](../Search_Space/index.rst) section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-Architecture\n",
    "\n",
    "The meta-architecture $f$ should encompasses all the considered neural networks from the search space. To define a meta-architecture usable with **DRAGON**, we create a class that inherits from `nn.Module`. The `__init__` function should take as input arguments defining a certain set of architecture and hyperparameters $\\{\\alpha, \\theta\\}$. Then, the `__forward__` function should take an input a variable $X$ and returns the prediction $\\hat{y} = f_{\\alpha,\\theta}(X)$.\n",
    "\n",
    "The main bricks to build neural networks within the **DRAGON** package are `dragon.search_space.cells.AdjMatrix` and `dragon.search_space.cells.Node`. The `AdjMatrix` creates a DAG and the `Node` a simple layer. Both bricks can be used to create models adapted to the task at hand. In this case we stay very simple with a single `AdjMatrix` embodying the neural network and a final `Node` to get the right output shape.\n",
    "\n",
    "Before the first training of a given neural network, the layers should be initialized with the right input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragon.search_space.dag_encoding import AdjMatrix, Node\n",
    "\n",
    "class MetaArchi(nn.Module):\n",
    "    def __init__(self, args, input_shape):\n",
    "        super().__init__()\n",
    "        # Number of features, here equals to 16\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        # We create the DAG using the WeightsAdjCell module\n",
    "        assert isinstance(args['Dag'], AdjMatrix), f\"The 'Dag' argument should be an 'AdjMatrix'. Got {type(args['Dag'])} instead.\"\n",
    "        self.dag = args['Dag']\n",
    "        self.dag.set(input_shape)\n",
    "\n",
    "        # We set the final layer\n",
    "        assert isinstance(args['Out'], Node), f\"The 'Out' argument should be a 'Node'. Got {type(args['Node'])} instead.\"\n",
    "        self.output = args[\"Out\"]\n",
    "        self.output.set(self.dag.output_shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.dag(X)\n",
    "        return self.output(out)\n",
    "    \n",
    "    def save(self, path):\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        full_path = os.path.join(path, \"best_model.pth\")\n",
    "        torch.save(self.state_dict(), full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments\n",
    "\n",
    "The `MetaArchi` class takes as input a dictionnary `args` containing one search space configuration ${\\alpha, \\theta}$. We now need to define what values $\\alpha$ and $\\theta$ can take. To keep it simple, we will only use `nn.Linear` and `nn.Identity` layers as candidate operations. Several ready-to-use candidate operations are available within `dragon.search_space.bricks_variables`. They are then used to build Directed Acyclic Graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of a generated DAG: NODES: [\n",
      "(combiner) add -- (name) <class 'dragon.search_space.bricks.basics.Identity'> -- (hp) {} -- (activation) Identity() -- , \n",
      "(combiner) mul -- (name) <class 'dragon.search_space.bricks.basics.MLP'> -- (hp) {'out_channels': 188} -- (activation) ELU(alpha=1.0) -- , \n",
      "(combiner) concat -- (name) <class 'dragon.search_space.bricks.basics.Identity'> -- (hp) {} -- (activation) ELU(alpha=1.0) -- , \n",
      "(combiner) concat -- (name) <class 'dragon.search_space.bricks.basics.Identity'> -- (hp) {} -- (activation) Sigmoid() -- , \n",
      "(combiner) mul -- (name) <class 'dragon.search_space.bricks.basics.MLP'> -- (hp) {'out_channels': 14} -- (activation) Sigmoid() -- , \n",
      "(combiner) add -- (name) <class 'dragon.search_space.bricks.basics.MLP'> -- (hp) {'out_channels': 461} -- (activation) GELU(approximate='none') -- , \n",
      "(combiner) concat -- (name) <class 'dragon.search_space.bricks.basics.Identity'> -- (hp) {} -- (activation) ELU(alpha=1.0) -- , \n",
      "(combiner) add -- (name) <class 'dragon.search_space.bricks.basics.Identity'> -- (hp) {} -- (activation) Identity() -- , \n",
      "(combiner) add -- (name) <class 'dragon.search_space.bricks.basics.MLP'> -- (hp) {'out_channels': 300} -- (activation) Tanh() -- , \n",
      "(combiner) mul -- (name) <class 'dragon.search_space.bricks.basics.MLP'> -- (hp) {'out_channels': 184} -- (activation) ELU(alpha=1.0) -- ] | MATRIX:[[0, 1, 1, 0, 1, 0, 0, 1, 1, 0], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "from dragon.search_space.bricks_variables import mlp_var, identity_var, operations_var, mlp_const_var, dag_var, node_var\n",
    "\n",
    "candidate_operations = operations_var(\"Candidate operations\", size=10, candidates=[mlp_var(\"MLP\"), identity_var(\"Identity\")])\n",
    "dag = dag_var(\"Dag\", candidate_operations)\n",
    "print(f'An example of a generated DAG: {dag.random()}')\n",
    "\n",
    "# For the last layer, we do not want the number of output channels to be optimized. It should be equal to the number of classes.\n",
    "out = node_var(\"Out\", operation=mlp_const_var('Operation', 10), activation_function=nn.Identity())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the elements `dag` and `out` we can generate composants to build a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"Dag\": dag.random(), \"Out\": out.random()}\n",
    "model = MetaArchi(args, input_shape=(16,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final search space is an array which contain all the structural elements of the architecture as well as eventually other elements for the training for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragon.search_space.base_variables import ArrayVar\n",
    "from dragon.search_operators.base_neighborhoods import ArrayInterval\n",
    "\n",
    "search_space = ArrayVar(dag, out, label=\"Search Space\", neighbor=ArrayInterval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "The search algorithm should minimize a certain loss function. Typically, it consists in training the model on a train set and then validate it on a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idx = test, accuracy = 0.9390539721043056\n",
      "For a given argument, accuracy =  93.91 %\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, data_loader):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
    "    model.train()\n",
    "    for _ in range(5):\n",
    "        for X,y in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            X = X.to(device)\n",
    "            y = y.squeeze().to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "def test_model(model, data_loader):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "      for X, y in data_loader:\n",
    "          X = X.to(device)\n",
    "          y = y.squeeze(1).to(device)\n",
    "          pred = model(X)\n",
    "          loss = loss_fn(pred, y).item()\n",
    "          test_loss += loss\n",
    "          prediction = pred.argmax(axis=1)\n",
    "          correct += (prediction == y).sum().item()\n",
    "    accuracy = correct/ len(data_loader.dataset)\n",
    "    return accuracy\n",
    "\n",
    "def loss_function(args, idx, *kwargs):\n",
    "    labels = [e.label for e in search_space]\n",
    "    args = dict(zip(labels, args))\n",
    "    model = MetaArchi(args, input_shape=(16,)).to(device)\n",
    "    model = train_model(model, train_loader)\n",
    "    accuracy = test_model(model, val_loader)\n",
    "    print(f\"Idx = {idx}, accuracy = {accuracy}\")\n",
    "    return 1 - accuracy, model\n",
    "\n",
    "loss, model = loss_function(search_space.random(), idx=\"test\")\n",
    "print(f'For a given argument, accuracy = ', np.round((1-loss)*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Algorithm\n",
    "\n",
    "We can use several search algorithms to optimize the structures from the search space. Here, we take the example of Mutant-UCB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-29 10:29:08,481 | WARNING | Use multiple processes if you want to use the distributed version.\n",
      "2026-01-29 10:29:08,484 | INFO | save/test_mutant already exists. Deleting it.\n",
      "2026-01-29 10:29:08,499 | INFO | The whole population has been created (size = 5), 5 have been randomy initialized.\n",
      "Idx = 0, accuracy = 0.9675560946027896\n",
      "2026-01-29 10:29:26,893 | INFO | Best found! 0.032443905397210426 < inf\n",
      "Idx = 1, accuracy = 0.645239539114615\n",
      "Idx = 2, accuracy = 0.8938750758035173\n",
      "Idx = 3, accuracy = 0.7283201940570042\n",
      "Idx = 4, accuracy = 0.930563978168587\n",
      "2026-01-29 10:30:02,498 | INFO | All models have been at least evaluated once, t = 5 < 20.\n",
      "2026-01-29 10:30:02,499 | INFO | After initialisation, it remains 15 iterations.\n",
      "üå°Ô∏è  Temperature adjusted to 0.7 (progress: 25.0%)\n",
      "2026-01-29 10:30:03,492 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.60):\n",
      "   Action: MUTATE on random\n",
      "   Reasoning: The search process is in its early stage (25% progress), and the population variance is relatively high (std_loss = 0.124532), indicating a diverse population. Given these conditions, the strategy hints suggest focusing on exploration. I have chosen to mutate a random individual, as this allows for the exploration of different parts of the search space without committing to a specific individual. The confidence level of 0.6 reflects the uncertainty in this decision, as there are multiple good options for exploration, but the choice of a random target and the mutate operation seems reasonable given the current state of the search.\n",
      "Idx = 4, accuracy = 0.9357186173438448\n",
      "üå°Ô∏è  Temperature adjusted to 0.4 (progress: 30.0%)\n",
      "2026-01-29 10:30:09,749 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.85):\n",
      "   Action: TRAIN on best\n",
      "   Reasoning: We are currently at 30% progress, which is the transition point from early stage to mid stage. Given that the best individual has only been trained once (N=1), there is still potential for improvement through further training. The population statistics show a moderate variance (std_loss = 0.125354), indicating that the population is somewhat diverse but not extremely so. Training the best individual will allow us to exploit its current performance and potentially reduce the loss further. The confidence level of 0.85 reflects the reasonable choice of continuing to train the best individual at this stage, with some supporting evidence from the population statistics and the current progress.\n",
      "Idx = 0, accuracy = 0.9805942995755003\n",
      "2026-01-29 10:30:17,423 | INFO | Best found! 0.01940570042449974 < 0.032443905397210426\n",
      "üå°Ô∏è  Temperature adjusted to 0.4 (progress: 35.0%)\n",
      "2026-01-29 10:30:18,441 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.85):\n",
      "   Action: TRAIN on best\n",
      "   Reasoning: We are currently at 35% progress, which is considered the mid-stage of the search process. The best individual has a low loss of 0.025925 and has only been trained twice, indicating potential for further improvement with additional training. The population statistics show a mean loss of 0.164554 and a standard deviation of 0.126760, suggesting that the population is still diverse and that training the best individual could lead to significant improvements. Given the current stage and the performance of the best individual, training it further seems like the most reasonable choice. The confidence level of 0.85 reflects the fact that this decision is based on a clear strategic choice with strong evidence, but also acknowledges that there is always some uncertainty in the outcome of the training process.\n",
      "Idx = 0, accuracy = 0.9857489387507581\n",
      "2026-01-29 10:30:26,361 | INFO | Best found! 0.014251061249241914 < 0.01940570042449974\n",
      "üå°Ô∏è  Temperature adjusted to 0.4 (progress: 40.0%)\n",
      "2026-01-29 10:30:27,251 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.90):\n",
      "   Action: TRAIN on best\n",
      "   Reasoning: The current progress is at 40%, which is in the mid-stage of the search process. The best individual has a low loss of 0.022034 and has been trained only 3 times. The best loss trend is improving, and the recent action distribution shows that TRAIN has a 100% success rate. Given this information, it is reasonable to continue training the best individual to further exploit its potential and improve its loss. The high confidence level of 0.9 reflects the clear strategic choice based on the strong evidence of the best individual's performance and the success of the TRAIN operation in the recent history.\n",
      "Idx = 0, accuracy = 0.9851425106124925\n",
      "üå°Ô∏è  Temperature adjusted to 0.4 (progress: 45.0%)\n",
      "2026-01-29 10:30:34,597 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.92):\n",
      "   Action: TRAIN on best\n",
      "   Reasoning: Given the current progress of 45% and the best individual's loss trend improving by -32.09% over the last 4 steps, it's clear that the strategy of training the best individual has been effective. The population statistics also indicate a mean loss of 0.163417 and a standard deviation of 0.128018, suggesting that while there is diversity, focusing on the best individual could lead to further improvement. The high confidence level of 0.92 reflects the success of the TRAIN operation in the recent history, with a 100% success rate and an average improvement of +0.010629. Since the best individual has been trained 4 times, which is not excessively high, continuing to train it seems like the most logical step to potentially achieve even better results without immediately introducing new, untested configurations through mutation or dropping an individual.\n",
      "Idx = 0, accuracy = 0.9899939357186174\n",
      "2026-01-29 10:30:40,917 | INFO | Best found! 0.01000606428138262 < 0.014251061249241914\n",
      "üå°Ô∏è  Temperature adjusted to 0.4 (progress: 50.0%)\n",
      "2026-01-29 10:30:41,770 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.92):\n",
      "   Action: TRAIN on best\n",
      "   Reasoning: The current progress is 50%, which is in the mid-stage of the search process. The best individual has been trained 5 times with a low loss of 0.018193, indicating a good exploitation of this individual. The recent history shows that training the best individual has been successful in improving the loss. The population statistics also show a relatively low standard deviation of loss, indicating that the population is converging. Given this information, continuing to train the best individual is a reasonable choice to further exploit its potential. The confidence level of 0.92 reflects the strong evidence from the recent history and the good performance of the best individual.\n",
      "Idx = 0, accuracy = 0.9896907216494846\n",
      "üå°Ô∏è  Temperature adjusted to 0.4 (progress: 55.0%)\n",
      "2026-01-29 10:30:54,485 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.92):\n",
      "   Action: TRAIN on best\n",
      "   Reasoning: The current progress is at 55%, which falls into the mid-stage of the search process. The best individual has been consistently improving with a low loss of 0.016879 and has been trained 6 times. The recent history shows that training the best individual has been successful in the past 5 steps, with an average improvement of +0.010001. Given the high success rate of the TRAIN operation and the consistent improvement of the best individual, it is reasonable to continue training the best individual to further exploit its potential. The confidence level of 0.92 reflects the high success rate of the TRAIN operation and the consistent improvement of the best individual, indicating a clear strategic choice with strong evidence.\n",
      "Idx = 0, accuracy = 0.9863553668890237\n",
      "üå°Ô∏è  Temperature adjusted to 0.4 (progress: 60.0%)\n",
      "2026-01-29 10:31:03,190 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.92):\n",
      "   Action: TRAIN on best\n",
      "   Reasoning: The current progress is 60%, which indicates we are in the mid-stage of the search process. The best individual has been trained 7 times and has shown significant improvement, with a loss of 0.016417. The recent history also shows that training the best individual has been successful in the past 5 steps, with an average improvement of +0.008873. Given this information, it is reasonable to continue training the best individual to further exploit its potential. The confidence level of 0.92 reflects the high success rate of training the best individual and the clear strategic choice to continue this approach.\n",
      "Idx = 0, accuracy = 0.9912067919951486\n",
      "2026-01-29 10:31:09,804 | INFO | Best found! 0.008793208004851394 < 0.01000606428138262\n",
      "üå°Ô∏è  Temperature adjusted to 0.4 (progress: 65.0%)\n",
      "2026-01-29 10:31:11,176 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.92):\n",
      "   Action: TRAIN on best\n",
      "   Reasoning: The current progress is at 65%, which is in the mid-stage of the search process. The best individual has been trained 8 times and has shown consistent improvement in loss. The recent history also shows that training the best individual has been successful in the past 5 steps, with a best loss trend improving by -25.49%. The population statistics indicate a mean loss of 0.162462 and a standard deviation of 0.129096, suggesting that the population is still diverse and can benefit from further exploitation. Given the success of the TRAIN operation in the recent past and the current stage of the search process, I have high confidence in continuing to train the best individual to further improve its loss. The confidence level of 0.92 reflects the strong evidence from the recent history and the current state of the population.\n",
      "Idx = 0, accuracy = 0.9915100060642814\n",
      "2026-01-29 10:31:18,641 | INFO | Best found! 0.008489993935718587 < 0.008793208004851394\n",
      "üå°Ô∏è  Temperature adjusted to 0.1 (progress: 70.0%)\n",
      "2026-01-29 10:31:19,574 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.85):\n",
      "   Action: DROP on worst\n",
      "   Reasoning: Given that the best individual has been trained 9 times and there's a risk of overfitting, it's essential to balance exploitation with exploration. The population's high variance (std_loss > 0.1) suggests diversity, which is good for exploration. However, since we are in the late stage (> 70% progress), focusing solely on exploitation might not be the best strategy. Dropping the worst individual and replacing it with a random one can help maintain diversity and potentially discover better configurations. The confidence level of 0.85 reflects a reasonable choice based on the current state of the search process, acknowledging the potential benefits of exploration while also considering the progress made so far.\n",
      "Idx = 5, accuracy = 0.8174651303820497\n",
      "üå°Ô∏è  Temperature adjusted to 0.1 (progress: 75.0%)\n",
      "2026-01-29 10:31:26,065 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.92):\n",
      "   Action: TRAIN on best\n",
      "   Reasoning: The current progress is at 75%, which indicates we are in the late stage of the search process. The best individual has been trained 9 times, but its loss is still improving, and the best loss trend is also improving (-19.26% over the last 5 steps). Given this information, it's reasonable to continue training the best individual to further exploit its potential. However, the risk of overfitting should be monitored. The confidence level of 0.92 reflects the strong evidence supporting the decision to continue training the best individual, given its consistent improvement and the current stage of the search process.\n",
      "Idx = 0, accuracy = 0.992116434202547\n",
      "2026-01-29 10:31:41,670 | INFO | Best found! 0.007883565797452974 < 0.008489993935718587\n",
      "üå°Ô∏è  Temperature adjusted to 0.1 (progress: 80.0%)\n",
      "2026-01-29 10:31:42,614 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.65):\n",
      "   Action: MUTATE on best\n",
      "   Reasoning: The current best individual has been trained 10 times, which poses a risk of overfitting. Given that the population is at 80% progress and the best loss trend is improving, it's essential to balance exploitation and exploration. Mutating the best individual allows for exploration while still leveraging the knowledge gained from the current best configuration. The confidence level of 0.65 reflects the uncertainty in whether this mutation will lead to a better individual, as there's no guarantee that the new configuration will outperform the current best. However, given the potential for overfitting and the need for continued exploration, this decision seems reasonable.\n",
      "Idx = 6, accuracy = 0.992116434202547\n",
      "üå°Ô∏è  Temperature adjusted to 0.1 (progress: 85.0%)\n",
      "2026-01-29 10:31:49,475 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.92):\n",
      "   Action: TRAIN on best\n",
      "   Reasoning: We are in the late stage of the search process (85% progress), and the best individual has shown significant improvement with training (100% success rate, avg improvement: +0.007701). The population statistics indicate a mean loss of 0.107752 and a standard deviation of 0.094091, suggesting that there is still room for improvement. Given the high success rate of training the best individual and the current stage of the search, it is reasonable to continue training the best individual to further exploit its potential. The confidence level of 0.92 reflects the strong evidence supporting this decision, as the best individual has consistently improved with training and the population is still diverse enough to benefit from exploitation.\n",
      "Idx = 6, accuracy = 0.9939357186173439\n",
      "2026-01-29 10:31:56,338 | INFO | Best found! 0.006064281382656134 < 0.007883565797452974\n",
      "üå°Ô∏è  Temperature adjusted to 0.1 (progress: 90.0%)\n",
      "2026-01-29 10:31:57,564 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.92):\n",
      "   Action: TRAIN on best\n",
      "   Reasoning: We are in the late stage of the search process (90% progress), and the best individual has shown significant improvement with training (49.02% reduction in loss over the last 5 steps). The population statistics indicate a stable population size and a relatively low standard deviation in loss, suggesting that the current best individual is a good candidate for further exploitation. The high confidence level (0.92) reflects the strong evidence supporting this decision, as the TRAIN operation has a 100% success rate and an average improvement of +0.006469. Furthermore, the best individual has only been trained twice, which is relatively low compared to other individuals, indicating that there is still potential for improvement with additional training.\n",
      "Idx = 6, accuracy = 0.9924196482716798\n",
      "üå°Ô∏è  Temperature adjusted to 0.1 (progress: 95.0%)\n",
      "2026-01-29 10:32:08,742 | INFO | HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ LLM Decision (confidence: 0.92):\n",
      "   Action: TRAIN on best\n",
      "   Reasoning: We are in the late stage of the search process (95% progress), and the best individual has shown significant improvement with training (88% success rate, avg improvement: +0.005496). The best loss trend is also improving (-52.52% over last 5 steps). Given this information, it is reasonable to continue training the best individual to further exploit its potential. The high confidence level (0.92) reflects the strong evidence supporting this decision, including the successful training history and the improving best loss trend.\n",
      "Idx = 6, accuracy = 0.9933292904790783\n",
      "2026-01-29 10:32:17,080 | INFO | Search algorithm is done. Min Loss = 0.006064281382656134\n"
     ]
    }
   ],
   "source": [
    "from dragon.search_algorithm.agentic import AgenticSearchAlgorithm, LLMPolicy, EnhancedLLMPolicy, AdaptiveLLMPolicy\n",
    "\n",
    "\n",
    "search_algorithm = AgenticSearchAlgorithm(search_space, save_dir=\"save/test_mutant\", T=20, N=5, K=5, E=0.01, evaluation=loss_function, \n",
    "                                          policy=AdaptiveLLMPolicy(api_key=api_key))\n",
    "search_algorithm.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-31 09:50:17,087 | WARNING | Use multiple processes if you want to use the distributed version.\n",
      "2025-07-31 09:50:17,090 | INFO | save/test_mutant already exists. Deleting it.\n",
      "2025-07-31 09:50:17,101 | INFO | The whole population has been created (size = 5), 5 have been randomy initialized.\n",
      "Idx = 0, accuracy = 0.957550030321407\n",
      "2025-07-31 09:50:38,240 | INFO | Best found! 0.04244996967859305 < inf\n",
      "Idx = 1, accuracy = 0.9272286234081262\n",
      "Idx = 2, accuracy = 0.9111582777440873\n",
      "Idx = 3, accuracy = 0.8523347483323226\n",
      "Idx = 4, accuracy = 0.8302001212856277\n",
      "2025-07-31 09:51:02,417 | INFO | All models have been at least evaluated once, t = 5 < 20.\n",
      "2025-07-31 09:51:02,419 | INFO | After initialisation, it remains 15 iterations.\n",
      "2025-07-31 09:51:02,423 | INFO | With p = 0.2 = 1 / 5, mutating 0 to 4\n",
      "Idx = 4, accuracy = 0.9730139478471801\n",
      "2025-07-31 09:51:21,197 | INFO | Best found! 0.026986052152819906 < 0.04244996967859305\n",
      "2025-07-31 09:51:21,209 | INFO | With p = 0.2 = 1 / 5, training 4 instead\n",
      "Idx = 4, accuracy = 0.9784718010915706\n",
      "2025-07-31 09:51:35,364 | INFO | Best found! 0.021528198908429386 < 0.026986052152819906\n",
      "2025-07-31 09:51:35,382 | INFO | With p = 0.4 = 2 / 5, training 4 instead\n",
      "Idx = 4, accuracy = 0.9860521528198909\n",
      "2025-07-31 09:51:48,524 | INFO | Best found! 0.013947847180109108 < 0.021528198908429386\n",
      "2025-07-31 09:51:48,538 | INFO | With p = 0.6 = 3 / 5, training 4 instead\n",
      "Idx = 4, accuracy = 0.9872650090964221\n",
      "2025-07-31 09:52:02,742 | INFO | Best found! 0.01273499090357788 < 0.013947847180109108\n",
      "2025-07-31 09:52:02,753 | INFO | With p = 0.8 = 4 / 5, mutating 4 to 5\n",
      "Idx = 5, accuracy = 0.9899939357186174\n",
      "2025-07-31 09:52:20,004 | INFO | Best found! 0.01000606428138262 < 0.01273499090357788\n",
      "2025-07-31 09:52:20,016 | INFO | With p = 0.2 = 1 / 5, training 5 instead\n",
      "Idx = 5, accuracy = 0.9909035779260158\n",
      "2025-07-31 09:52:41,832 | INFO | Best found! 0.0090964220739842 < 0.01000606428138262\n",
      "2025-07-31 09:52:41,843 | INFO | With p = 0.4 = 2 / 5, training 5 instead\n",
      "Idx = 5, accuracy = 0.9802910855063675\n",
      "2025-07-31 09:52:57,462 | INFO | With p = 0.6 = 3 / 5, mutating 5 to 6\n",
      "Idx = 6, accuracy = 0.9899939357186174\n",
      "2025-07-31 09:53:11,457 | INFO | With p = 0.2 = 1 / 5, training 6 instead\n",
      "Idx = 6, accuracy = 0.990600363856883\n",
      "2025-07-31 09:53:39,497 | INFO | With p = 0.4 = 2 / 5, mutating 6 to 7\n",
      "Idx = 7, accuracy = 0.9875682231655549\n",
      "2025-07-31 09:53:53,797 | INFO | With p = 0.2 = 1 / 5, training 7 instead\n",
      "Idx = 7, accuracy = 0.9902971497877502\n",
      "2025-07-31 09:54:09,322 | INFO | With p = 0.4 = 2 / 5, training 7 instead\n",
      "Idx = 7, accuracy = 0.9899939357186174\n",
      "2025-07-31 09:54:31,517 | INFO | With p = 0.4 = 2 / 5, mutating 6 to 8\n",
      "Idx = 8, accuracy = 0.9899939357186174\n",
      "2025-07-31 09:54:47,487 | INFO | With p = 0.2 = 1 / 5, training 8 instead\n",
      "Idx = 8, accuracy = 0.9915100060642814\n",
      "2025-07-31 09:55:08,448 | INFO | Best found! 0.008489993935718587 < 0.0090964220739842\n",
      "2025-07-31 09:55:08,457 | INFO | With p = 0.4 = 2 / 5, mutating 8 to 9\n",
      "Idx = 9, accuracy = 0.992116434202547\n",
      "2025-07-31 09:55:19,700 | INFO | Best found! 0.007883565797452974 < 0.008489993935718587\n",
      "2025-07-31 09:55:19,709 | INFO | Search algorithm is done. Min Loss = 0.007883565797452974\n"
     ]
    }
   ],
   "source": [
    "from dragon.search_algorithm.mutant_ucb import Mutant_UCB\n",
    "\n",
    "search_algorithm = Mutant_UCB(search_space, save_dir=\"save/test_mutant\", T=20, N=5, K=5, E=0.01, evaluation=loss_function)\n",
    "search_algorithm.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Graph\n",
    "\n",
    "After the optimization, it is possible to load the best graph and draw the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model giving a score of  99.21 %:\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: save/_mutant/best_archi Pages: 1 -->\n",
       "<svg width=\"504pt\" height=\"548pt\"\n",
       " viewBox=\"0.00 0.00 504.30 548.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 544)\">\n",
       "<title>save/_mutant/best_archi</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-544 500.3,-544 500.3,4 -4,4\"/>\n",
       "<!-- Input -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Input</title>\n",
       "<path fill=\"#ef5675\" stroke=\"black\" d=\"M306.8,-540C306.8,-540 263.8,-540 263.8,-540 257.8,-540 251.8,-534 251.8,-528 251.8,-528 251.8,-516 251.8,-516 251.8,-510 257.8,-504 263.8,-504 263.8,-504 306.8,-504 306.8,-504 312.8,-504 318.8,-510 318.8,-516 318.8,-516 318.8,-528 318.8,-528 318.8,-534 312.8,-540 306.8,-540\"/>\n",
       "<text text-anchor=\"middle\" x=\"285.3\" y=\"-517\" font-family=\"sans-serif\" font-size=\"20.00\" fill=\"#ececec\">Input</text>\n",
       "</g>\n",
       "<!-- concat,MLP,277,LeakyReLU -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>concat,MLP,277,LeakyReLU</title>\n",
       "<path fill=\"#ffa600\" stroke=\"black\" d=\"M326.8,-468C326.8,-468 81.8,-468 81.8,-468 75.8,-468 69.8,-462 69.8,-456 69.8,-456 69.8,-444 69.8,-444 69.8,-438 75.8,-432 81.8,-432 81.8,-432 326.8,-432 326.8,-432 332.8,-432 338.8,-438 338.8,-444 338.8,-444 338.8,-456 338.8,-456 338.8,-462 332.8,-468 326.8,-468\"/>\n",
       "<text text-anchor=\"middle\" x=\"204.3\" y=\"-445\" font-family=\"sans-serif\" font-size=\"20.00\">concat,MLP,277,LeakyReLU</text>\n",
       "</g>\n",
       "<!-- Input&#45;&gt;concat,MLP,277,LeakyReLU -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Input&#45;&gt;concat,MLP,277,LeakyReLU</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M265.28,-503.7C255.18,-494.97 242.77,-484.24 231.78,-474.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"233.95,-471.99 224.09,-468.1 229.37,-477.29 233.95,-471.99\"/>\n",
       "</g>\n",
       "<!-- mul,Identity,GELU 1 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>mul,Identity,GELU 1</title>\n",
       "<path fill=\"#ffa600\" stroke=\"black\" d=\"M455.8,-324C455.8,-324 278.8,-324 278.8,-324 272.8,-324 266.8,-318 266.8,-312 266.8,-312 266.8,-300 266.8,-300 266.8,-294 272.8,-288 278.8,-288 278.8,-288 455.8,-288 455.8,-288 461.8,-288 467.8,-294 467.8,-300 467.8,-300 467.8,-312 467.8,-312 467.8,-318 461.8,-324 455.8,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"367.3\" y=\"-301\" font-family=\"sans-serif\" font-size=\"20.00\">mul,Identity,GELU 1</text>\n",
       "</g>\n",
       "<!-- Input&#45;&gt;mul,Identity,GELU 1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Input&#45;&gt;mul,Identity,GELU 1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M314.16,-503.88C326.76,-494.84 340.43,-482.59 348.3,-468 371.2,-425.53 371.95,-367.73 369.95,-334.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"373.44,-333.92 369.22,-324.2 366.46,-334.43 373.44,-333.92\"/>\n",
       "</g>\n",
       "<!-- concat,MLP,310,Tanh -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>concat,MLP,310,Tanh</title>\n",
       "<path fill=\"#ffa600\" stroke=\"black\" d=\"M327.3,-252C327.3,-252 141.3,-252 141.3,-252 135.3,-252 129.3,-246 129.3,-240 129.3,-240 129.3,-228 129.3,-228 129.3,-222 135.3,-216 141.3,-216 141.3,-216 327.3,-216 327.3,-216 333.3,-216 339.3,-222 339.3,-228 339.3,-228 339.3,-240 339.3,-240 339.3,-246 333.3,-252 327.3,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.3\" y=\"-229\" font-family=\"sans-serif\" font-size=\"20.00\">concat,MLP,310,Tanh</text>\n",
       "</g>\n",
       "<!-- Input&#45;&gt;concat,MLP,310,Tanh -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Input&#45;&gt;concat,MLP,310,Tanh</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.68,-516.97C196.16,-509.69 88.62,-492.77 60.3,-468 8.74,-422.9 17.73,-391.37 5.3,-324 2.4,-308.27 -4.65,-300.52 5.3,-288 20.24,-269.21 69.81,-256.5 119.03,-248.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.87,-251.65 129.18,-246.6 118.75,-244.74 119.87,-251.65\"/>\n",
       "</g>\n",
       "<!-- concat,MLP,264,Tanh -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>concat,MLP,264,Tanh</title>\n",
       "<path fill=\"#ffa600\" stroke=\"black\" d=\"M460.3,-180C460.3,-180 274.3,-180 274.3,-180 268.3,-180 262.3,-174 262.3,-168 262.3,-168 262.3,-156 262.3,-156 262.3,-150 268.3,-144 274.3,-144 274.3,-144 460.3,-144 460.3,-144 466.3,-144 472.3,-150 472.3,-156 472.3,-156 472.3,-168 472.3,-168 472.3,-174 466.3,-180 460.3,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"367.3\" y=\"-157\" font-family=\"sans-serif\" font-size=\"20.00\">concat,MLP,264,Tanh</text>\n",
       "</g>\n",
       "<!-- Input&#45;&gt;concat,MLP,264,Tanh -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Input&#45;&gt;concat,MLP,264,Tanh</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M319.2,-514.5C378.85,-500.87 496.3,-463.34 496.3,-379 496.3,-379 496.3,-379 496.3,-305 496.3,-251.81 446.1,-209.72 408.33,-185.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"409.87,-182.42 399.52,-180.13 406.18,-188.37 409.87,-182.42\"/>\n",
       "</g>\n",
       "<!-- mul,Identity,GELU -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>mul,Identity,GELU</title>\n",
       "<path fill=\"#ffa600\" stroke=\"black\" d=\"M230.8,-396C230.8,-396 69.8,-396 69.8,-396 63.8,-396 57.8,-390 57.8,-384 57.8,-384 57.8,-372 57.8,-372 57.8,-366 63.8,-360 69.8,-360 69.8,-360 230.8,-360 230.8,-360 236.8,-360 242.8,-366 242.8,-372 242.8,-372 242.8,-384 242.8,-384 242.8,-390 236.8,-396 230.8,-396\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.3\" y=\"-373\" font-family=\"sans-serif\" font-size=\"20.00\">mul,Identity,GELU</text>\n",
       "</g>\n",
       "<!-- concat,MLP,277,LeakyReLU&#45;&gt;mul,Identity,GELU -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>concat,MLP,277,LeakyReLU&#45;&gt;mul,Identity,GELU</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M190.95,-431.7C184.55,-423.39 176.74,-413.28 169.7,-404.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"172.38,-401.88 163.5,-396.1 166.83,-406.16 172.38,-401.88\"/>\n",
       "</g>\n",
       "<!-- concat,MLP,277,LeakyReLU&#45;&gt;mul,Identity,GELU 1 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>concat,MLP,277,LeakyReLU&#45;&gt;mul,Identity,GELU 1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M223.96,-431.87C252.85,-406.71 306.86,-359.65 339.71,-331.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"342.33,-333.4 347.57,-324.19 337.73,-328.12 342.33,-333.4\"/>\n",
       "</g>\n",
       "<!-- concat,Identity,Identity -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>concat,Identity,Identity</title>\n",
       "<path fill=\"#ffa600\" stroke=\"black\" d=\"M236.3,-324C236.3,-324 26.3,-324 26.3,-324 20.3,-324 14.3,-318 14.3,-312 14.3,-312 14.3,-300 14.3,-300 14.3,-294 20.3,-288 26.3,-288 26.3,-288 236.3,-288 236.3,-288 242.3,-288 248.3,-294 248.3,-300 248.3,-300 248.3,-312 248.3,-312 248.3,-318 242.3,-324 236.3,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"131.3\" y=\"-301\" font-family=\"sans-serif\" font-size=\"20.00\">concat,Identity,Identity</text>\n",
       "</g>\n",
       "<!-- mul,Identity,GELU&#45;&gt;concat,Identity,Identity -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>mul,Identity,GELU&#45;&gt;concat,Identity,Identity</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.61,-359.7C143.49,-351.9 140.94,-342.51 138.58,-333.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"141.94,-332.84 135.94,-324.1 135.19,-334.67 141.94,-332.84\"/>\n",
       "</g>\n",
       "<!-- concat,Identity,Identity&#45;&gt;concat,MLP,310,Tanh -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>concat,Identity,Identity&#45;&gt;concat,MLP,310,Tanh</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.5,-287.88C169.72,-278.89 186.09,-267.76 200.41,-258.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"202.71,-260.71 209.01,-252.19 198.77,-254.92 202.71,-260.71\"/>\n",
       "</g>\n",
       "<!-- mul,Identity,GELU 1&#45;&gt;concat,MLP,310,Tanh -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>mul,Identity,GELU 1&#45;&gt;concat,MLP,310,Tanh</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M334.77,-287.88C317.05,-278.55 294.95,-266.92 275.99,-256.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"277.44,-253.75 266.96,-252.19 274.18,-259.94 277.44,-253.75\"/>\n",
       "</g>\n",
       "<!-- mul,Identity,GELU 1&#45;&gt;concat,MLP,264,Tanh -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>mul,Identity,GELU 1&#45;&gt;concat,MLP,264,Tanh</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M367.3,-287.87C367.3,-263.67 367.3,-219.21 367.3,-190.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"370.8,-190.19 367.3,-180.19 363.8,-190.19 370.8,-190.19\"/>\n",
       "</g>\n",
       "<!-- concat,MLP,310,Tanh&#45;&gt;concat,MLP,264,Tanh -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>concat,MLP,310,Tanh&#45;&gt;concat,MLP,264,Tanh</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M266.84,-215.88C284.55,-206.55 306.66,-194.92 325.62,-184.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"327.42,-187.94 334.64,-180.19 324.16,-181.75 327.42,-187.94\"/>\n",
       "</g>\n",
       "<!-- add,Identity,LeakyReLU -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>add,Identity,LeakyReLU</title>\n",
       "<path fill=\"#ffa600\" stroke=\"black\" d=\"M406.8,-108C406.8,-108 193.8,-108 193.8,-108 187.8,-108 181.8,-102 181.8,-96 181.8,-96 181.8,-84 181.8,-84 181.8,-78 187.8,-72 193.8,-72 193.8,-72 406.8,-72 406.8,-72 412.8,-72 418.8,-78 418.8,-84 418.8,-84 418.8,-96 418.8,-96 418.8,-102 412.8,-108 406.8,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"300.3\" y=\"-85\" font-family=\"sans-serif\" font-size=\"20.00\">add,Identity,LeakyReLU</text>\n",
       "</g>\n",
       "<!-- concat,MLP,310,Tanh&#45;&gt;add,Identity,LeakyReLU -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>concat,MLP,310,Tanh&#45;&gt;add,Identity,LeakyReLU</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M235.37,-215.74C237.11,-197.15 241.62,-167.13 253.3,-144 258.48,-133.75 266.14,-123.92 273.78,-115.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"276.31,-117.99 280.71,-108.35 271.26,-113.14 276.31,-117.99\"/>\n",
       "</g>\n",
       "<!-- concat,MLP,264,Tanh&#45;&gt;add,Identity,LeakyReLU -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>concat,MLP,264,Tanh&#45;&gt;add,Identity,LeakyReLU</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M350.74,-143.7C342.63,-135.22 332.71,-124.86 323.83,-115.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"326.12,-112.91 316.67,-108.1 321.06,-117.75 326.12,-112.91\"/>\n",
       "</g>\n",
       "<!-- MLP,10,Identity() -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>MLP,10,Identity()</title>\n",
       "<path fill=\"#ef5675\" stroke=\"black\" d=\"M374.8,-36C374.8,-36 225.8,-36 225.8,-36 219.8,-36 213.8,-30 213.8,-24 213.8,-24 213.8,-12 213.8,-12 213.8,-6 219.8,0 225.8,0 225.8,0 374.8,0 374.8,0 380.8,0 386.8,-6 386.8,-12 386.8,-12 386.8,-24 386.8,-24 386.8,-30 380.8,-36 374.8,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"300.3\" y=\"-13\" font-family=\"sans-serif\" font-size=\"20.00\" fill=\"#ececec\">MLP,10,Identity()</text>\n",
       "</g>\n",
       "<!-- add,Identity,LeakyReLU&#45;&gt;MLP,10,Identity() -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>add,Identity,LeakyReLU&#45;&gt;MLP,10,Identity()</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M300.3,-71.7C300.3,-63.98 300.3,-54.71 300.3,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"303.8,-46.1 300.3,-36.1 296.8,-46.1 303.8,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x70439152e710>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "from dragon.utils.plot_functions import draw_cell, load_archi, str_operations\n",
    "\n",
    "def draw_graph(n_dag, m_dag, output_file, act=\"Identity()\", name=\"Input\"):\n",
    "    G = graphviz.Digraph(output_file, format='pdf',\n",
    "                            node_attr={'nodesep': '0.02', 'shape': 'box', 'rankstep': '0.02', 'fontsize': '20', \"fontname\": \"sans-serif\"})\n",
    "\n",
    "    G, g_nodes = draw_cell(G, n_dag, m_dag, \"#ffa600\", [], name_input=name,\n",
    "                            color_input=\"#ef5675\")\n",
    "    G.node(','.join([\"MLP\", \"10\", act]), style=\"rounded,filled\", color=\"black\", fillcolor=\"#ef5675\", fontcolor=\"#ECECEC\")\n",
    "    G.edge(g_nodes[-1], ','.join([\"MLP\", \"10\", act]))\n",
    "    return G\n",
    "\n",
    "best_model = load_archi(\"save/test_mutant/best_model/x.pkl\")\n",
    "labels = [e.label for e in search_space]\n",
    "best_model = dict(zip(labels, best_model))\n",
    "m_dag = best_model['Dag'].matrix\n",
    "n_dag = str_operations(best_model[\"Dag\"].operations)\n",
    "\n",
    "graph = draw_graph(n_dag, m_dag, \"save/_mutant/best_archi\")\n",
    "print(f'Model giving a score of ', np.round((1-search_algorithm.min_loss)*100, 2), '%:')\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: SVC / RandomForest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-30 08:31:47,051] A new study created in memory with name: no-name-56c0c993-5fe9-4734-b454-5c7296a0f970\n",
      "[I 2024-09-30 08:31:47,147] Trial 0 finished with value: 0.9802910855063675 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 9}. Best is trial 0 with value: 0.9802910855063675.\n",
      "[I 2024-09-30 08:31:47,192] Trial 1 finished with value: 0.7947240751970891 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 3}. Best is trial 0 with value: 0.9802910855063675.\n",
      "[I 2024-09-30 08:31:53,258] Trial 2 finished with value: 0.11552456033959976 and parameters: {'classifier': 'SVC', 'svc_c': 107434903.85230298}. Best is trial 0 with value: 0.9802910855063675.\n",
      "[I 2024-09-30 08:31:59,078] Trial 3 finished with value: 0.11552456033959976 and parameters: {'classifier': 'SVC', 'svc_c': 76.05790764453474}. Best is trial 0 with value: 0.9802910855063675.\n",
      "[I 2024-09-30 08:32:04,722] Trial 4 finished with value: 0.11552456033959976 and parameters: {'classifier': 'SVC', 'svc_c': 1278143.6692545111}. Best is trial 0 with value: 0.9802910855063675.\n",
      "[I 2024-09-30 08:32:10,627] Trial 5 finished with value: 0.11552456033959976 and parameters: {'classifier': 'SVC', 'svc_c': 4396269782.010601}. Best is trial 0 with value: 0.9802910855063675.\n",
      "[I 2024-09-30 08:32:15,738] Trial 6 finished with value: 0.10278956943602183 and parameters: {'classifier': 'SVC', 'svc_c': 0.00011304122770204807}. Best is trial 0 with value: 0.9802910855063675.\n",
      "[I 2024-09-30 08:32:15,813] Trial 7 finished with value: 0.9642207398423287 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 7}. Best is trial 0 with value: 0.9802910855063675.\n",
      "[I 2024-09-30 08:32:15,849] Trial 8 finished with value: 0.7404487568223166 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 2}. Best is trial 0 with value: 0.9802910855063675.\n",
      "[I 2024-09-30 08:32:21,528] Trial 9 finished with value: 0.11552456033959976 and parameters: {'classifier': 'SVC', 'svc_c': 1432989.5573470553}. Best is trial 0 with value: 0.9802910855063675.\n",
      "[I 2024-09-30 08:32:21,632] Trial 10 finished with value: 0.9866585809581565 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 30}. Best is trial 10 with value: 0.9866585809581565.\n",
      "[I 2024-09-30 08:32:21,745] Trial 11 finished with value: 0.9887810794420862 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 32}. Best is trial 11 with value: 0.9887810794420862.\n",
      "[I 2024-09-30 08:32:21,857] Trial 12 finished with value: 0.9878714372346877 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 32}. Best is trial 11 with value: 0.9887810794420862.\n",
      "[I 2024-09-30 08:32:21,952] Trial 13 finished with value: 0.9851425106124925 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 32}. Best is trial 11 with value: 0.9887810794420862.\n",
      "[I 2024-09-30 08:32:22,047] Trial 14 finished with value: 0.9848392965433597 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14}. Best is trial 11 with value: 0.9887810794420862.\n",
      "[I 2024-09-30 08:32:22,150] Trial 15 finished with value: 0.9893875075803518 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 17}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:22,253] Trial 16 finished with value: 0.9887810794420862 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 17}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:22,357] Trial 17 finished with value: 0.9887810794420862 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 16}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:22,461] Trial 18 finished with value: 0.9884778653729533 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 19}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:22,517] Trial 19 finished with value: 0.8750758035172832 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 4}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:22,627] Trial 20 finished with value: 0.9854457246816253 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:22,740] Trial 21 finished with value: 0.9869617950272893 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 20}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:22,840] Trial 22 finished with value: 0.9893875075803518 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 21}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:22,939] Trial 23 finished with value: 0.9872650090964221 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 24}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:23,033] Trial 24 finished with value: 0.9796846573681018 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 10}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:23,131] Trial 25 finished with value: 0.9845360824742269 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 23}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:23,197] Trial 26 finished with value: 0.9408732565191025 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 6}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:23,292] Trial 27 finished with value: 0.9863553668890237 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 23}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:23,381] Trial 28 finished with value: 0.9857489387507581 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:23,468] Trial 29 finished with value: 0.9881746513038205 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 23}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:23,552] Trial 30 finished with value: 0.9839296543359611 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 10}. Best is trial 15 with value: 0.9893875075803518.\n",
      "[I 2024-09-30 08:32:23,641] Trial 31 finished with value: 0.9896907216494846 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 16}. Best is trial 31 with value: 0.9896907216494846.\n",
      "[I 2024-09-30 08:32:23,733] Trial 32 finished with value: 0.990600363856883 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 17}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:23,826] Trial 33 finished with value: 0.9845360824742269 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 15}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:23,917] Trial 34 finished with value: 0.9869617950272893 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:28,852] Trial 35 finished with value: 0.10278956943602183 and parameters: {'classifier': 'SVC', 'svc_c': 6.511115455954505e-10}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:28,920] Trial 36 finished with value: 0.957550030321407 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 7}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:33,812] Trial 37 finished with value: 0.10278956943602183 and parameters: {'classifier': 'SVC', 'svc_c': 0.00035066537122351867}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:33,893] Trial 38 finished with value: 0.9796846573681018 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 9}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:39,367] Trial 39 finished with value: 0.10278956943602183 and parameters: {'classifier': 'SVC', 'svc_c': 3.267386529006129e-09}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:39,460] Trial 40 finished with value: 0.9860521528198909 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 18}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:39,548] Trial 41 finished with value: 0.989084293511219 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 25}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:39,646] Trial 42 finished with value: 0.9878714372346877 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 26}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:39,762] Trial 43 finished with value: 0.9884778653729533 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 19}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:39,878] Trial 44 finished with value: 0.9875682231655549 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 26}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:46,818] Trial 45 finished with value: 0.11552456033959976 and parameters: {'classifier': 'SVC', 'svc_c': 84.19317057488534}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:46,909] Trial 46 finished with value: 0.9869617950272893 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 20}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:46,944] Trial 47 finished with value: 0.7195269860521528 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 2}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:47,030] Trial 48 finished with value: 0.9875682231655549 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 16}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:47,123] Trial 49 finished with value: 0.9857489387507581 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 27}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:52,568] Trial 50 finished with value: 0.10278956943602183 and parameters: {'classifier': 'SVC', 'svc_c': 0.00049795530410561}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:52,660] Trial 51 finished with value: 0.9878714372346877 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 29}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:52,753] Trial 52 finished with value: 0.9857489387507581 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 21}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:52,847] Trial 53 finished with value: 0.9866585809581565 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 30}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:52,947] Trial 54 finished with value: 0.9869617950272893 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:53,048] Trial 55 finished with value: 0.9884778653729533 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 17}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:53,148] Trial 56 finished with value: 0.9875682231655549 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 22}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:53,244] Trial 57 finished with value: 0.9887810794420862 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 31}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:53,336] Trial 58 finished with value: 0.989084293511219 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 25}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:53,429] Trial 59 finished with value: 0.9869617950272893 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 17}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:53,478] Trial 60 finished with value: 0.8641600970285022 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 4}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:53,575] Trial 61 finished with value: 0.9857489387507581 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 24}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:53,671] Trial 62 finished with value: 0.9872650090964221 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 32}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:53,766] Trial 63 finished with value: 0.9875682231655549 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 28}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:53,863] Trial 64 finished with value: 0.9869617950272893 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 21}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:53,960] Trial 65 finished with value: 0.9866585809581565 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 19}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:54,054] Trial 66 finished with value: 0.9893875075803518 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 25}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:54,140] Trial 67 finished with value: 0.9875682231655549 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 15}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:54,224] Trial 68 finished with value: 0.9860521528198909 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:59,763] Trial 69 finished with value: 0.10278956943602183 and parameters: {'classifier': 'SVC', 'svc_c': 2.4446970641424645e-07}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:59,851] Trial 70 finished with value: 0.9869617950272893 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 25}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:32:59,940] Trial 71 finished with value: 0.9884778653729533 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 27}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:00,036] Trial 72 finished with value: 0.9833232261976955 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 22}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:00,134] Trial 73 finished with value: 0.9872650090964221 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 18}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:00,223] Trial 74 finished with value: 0.9875682231655549 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 24}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:00,311] Trial 75 finished with value: 0.9839296543359611 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:00,397] Trial 76 finished with value: 0.9863553668890237 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 32}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:00,483] Trial 77 finished with value: 0.9872650090964221 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 20}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:00,568] Trial 78 finished with value: 0.9863553668890237 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 25}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:06,825] Trial 79 finished with value: 0.11552456033959976 and parameters: {'classifier': 'SVC', 'svc_c': 1.7260909483357085}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:06,919] Trial 80 finished with value: 0.9893875075803518 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 29}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:07,018] Trial 81 finished with value: 0.9875682231655549 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 23}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:07,110] Trial 82 finished with value: 0.9893875075803518 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 28}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:07,207] Trial 83 finished with value: 0.9866585809581565 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 28}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:07,301] Trial 84 finished with value: 0.9899939357186174 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 29}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:07,391] Trial 85 finished with value: 0.9869617950272893 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 28}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:07,445] Trial 86 finished with value: 0.9129775621588841 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 5}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:07,534] Trial 87 finished with value: 0.9887810794420862 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 21}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:07,620] Trial 88 finished with value: 0.9869617950272893 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:07,700] Trial 89 finished with value: 0.9721043056397817 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:07,792] Trial 90 finished with value: 0.9863553668890237 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 16}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:07,886] Trial 91 finished with value: 0.9878714372346877 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 25}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:07,977] Trial 92 finished with value: 0.9884778653729533 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 29}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:08,075] Trial 93 finished with value: 0.9881746513038205 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 18}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:08,173] Trial 94 finished with value: 0.9875682231655549 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 26}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:08,267] Trial 95 finished with value: 0.9878714372346877 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 22}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:08,368] Trial 96 finished with value: 0.9851425106124925 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 30}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:14,144] Trial 97 finished with value: 0.11552456033959976 and parameters: {'classifier': 'SVC', 'svc_c': 33766.72119670471}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:14,233] Trial 98 finished with value: 0.9884778653729533 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 23}. Best is trial 32 with value: 0.990600363856883.\n",
      "[I 2024-09-30 08:33:14,320] Trial 99 finished with value: 0.9884778653729533 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 20}. Best is trial 32 with value: 0.990600363856883.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Accuracy:  99.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    classifier_name = trial.suggest_categorical('classifier', ['SVC', 'RandomForest'])\n",
    "    if classifier_name == 'SVC':\n",
    "         svc_c = trial.suggest_float('svc_c', 1e-10, 1e10, log=True)\n",
    "         classifier_obj = SVC(C=svc_c, gamma='auto')\n",
    "    else:\n",
    "        rf_max_depth = trial.suggest_int('rf_max_depth', 2, 32, log=True)\n",
    "        classifier_obj = RandomForestClassifier(max_depth=rf_max_depth, n_estimators=10)\n",
    "    classifier_obj.fit(X_train, y_train, )\n",
    "    pred = classifier_obj.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, pred)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(f\"\\nBest Accuracy: \", np.round(study.best_value,2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dragon-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
